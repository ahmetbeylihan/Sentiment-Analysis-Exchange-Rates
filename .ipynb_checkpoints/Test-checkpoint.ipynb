{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import shakespeare, machado, stopwords\n",
    "w = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'S',\n",
       " 'TRUMAN',\n",
       " 'S',\n",
       " 'ADDRESS',\n",
       " 'BEFORE',\n",
       " 'A',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'It',\n",
       " 'is',\n",
       " 'with',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'before',\n",
       " 'you',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'colleagues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Only',\n",
       " 'yesterday',\n",
       " 'we',\n",
       " 'laid',\n",
       " 'to',\n",
       " 'rest',\n",
       " 'the',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'our',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'At',\n",
       " 'a',\n",
       " 'time',\n",
       " 'like',\n",
       " 'this',\n",
       " 'words',\n",
       " 'are',\n",
       " 'inadequate',\n",
       " 'The',\n",
       " 'most',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'Yet',\n",
       " 'in',\n",
       " 'this',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'when',\n",
       " 'world',\n",
       " 'events',\n",
       " 'are',\n",
       " 'moving',\n",
       " 'so',\n",
       " 'rapidly',\n",
       " 'our',\n",
       " 'silence',\n",
       " 'might',\n",
       " 'be',\n",
       " 'misunderstood',\n",
       " 'and',\n",
       " 'might',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'to',\n",
       " 'our',\n",
       " 'enemies',\n",
       " 'In',\n",
       " 'His',\n",
       " 'infinite',\n",
       " 'wisdom',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'to',\n",
       " 'take',\n",
       " 'from',\n",
       " 'us',\n",
       " 'a',\n",
       " 'great',\n",
       " 'man',\n",
       " 'who',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'was',\n",
       " 'beloved',\n",
       " 'by',\n",
       " 'all',\n",
       " 'humanity',\n",
       " 'No',\n",
       " 'man',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'tremendous',\n",
       " 'void',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'passing',\n",
       " 'of',\n",
       " 'that',\n",
       " 'noble',\n",
       " 'soul',\n",
       " 'No',\n",
       " 'words',\n",
       " 'can',\n",
       " 'ease',\n",
       " 'the',\n",
       " 'aching',\n",
       " 'hearts',\n",
       " 'of',\n",
       " 'untold',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'every',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'and',\n",
       " 'color',\n",
       " 'The',\n",
       " 'world',\n",
       " 'knows',\n",
       " 'it',\n",
       " 'has',\n",
       " 'lost',\n",
       " 'a',\n",
       " 'heroic',\n",
       " 'champion',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'Tragic',\n",
       " 'fate',\n",
       " 'has',\n",
       " 'thrust',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'grave',\n",
       " 'responsibilities',\n",
       " 'We',\n",
       " 'must',\n",
       " 'carry',\n",
       " 'on',\n",
       " 'Our',\n",
       " 'departed',\n",
       " 'leader',\n",
       " 'never',\n",
       " 'looked',\n",
       " 'backward',\n",
       " 'He',\n",
       " 'looked',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'forward',\n",
       " 'That',\n",
       " 'is',\n",
       " 'what',\n",
       " 'he',\n",
       " 'would',\n",
       " 'want',\n",
       " 'us',\n",
       " 'to',\n",
       " 'do',\n",
       " 'That',\n",
       " 'is',\n",
       " 'what',\n",
       " 'America',\n",
       " 'will',\n",
       " 'do',\n",
       " 'So',\n",
       " 'much',\n",
       " 'blood',\n",
       " 'has',\n",
       " 'already',\n",
       " 'been',\n",
       " 'shed',\n",
       " 'for',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'we',\n",
       " 'cherish',\n",
       " 'and',\n",
       " 'for',\n",
       " 'which',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'lived',\n",
       " 'and',\n",
       " 'died',\n",
       " 'that',\n",
       " 'we',\n",
       " 'dare',\n",
       " 'not',\n",
       " 'permit',\n",
       " 'even',\n",
       " 'a',\n",
       " 'momentary',\n",
       " 'pause',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hard',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'victory',\n",
       " 'Today',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'America',\n",
       " 'for',\n",
       " 'enlightened',\n",
       " 'leadership',\n",
       " 'to',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'progress',\n",
       " 'Such',\n",
       " 'a',\n",
       " 'leadership',\n",
       " 'requires',\n",
       " 'vision',\n",
       " 'courage',\n",
       " 'and',\n",
       " 'tolerance',\n",
       " 'It',\n",
       " 'can',\n",
       " 'be',\n",
       " 'provided',\n",
       " 'only',\n",
       " 'by',\n",
       " 'a',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'deeply',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'ideals',\n",
       " 'With',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'I',\n",
       " 'call',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'Americans',\n",
       " 'to',\n",
       " 'help',\n",
       " 'me',\n",
       " 'keep',\n",
       " 'our',\n",
       " 'nation',\n",
       " 'united',\n",
       " 'in',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'eloquently',\n",
       " 'proclaimed',\n",
       " 'by',\n",
       " 'Franklin',\n",
       " 'Roosevelt',\n",
       " 'I',\n",
       " 'want',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'assure',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'those',\n",
       " 'who',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'liberty',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'world',\n",
       " 'that',\n",
       " 'I',\n",
       " 'will',\n",
       " 'support',\n",
       " 'and',\n",
       " 'defend',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'with',\n",
       " 'all',\n",
       " 'my',\n",
       " 'strength',\n",
       " 'and',\n",
       " 'all',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'That',\n",
       " 'is',\n",
       " 'my',\n",
       " 'duty',\n",
       " 'and',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'shirk',\n",
       " 'it',\n",
       " 'So',\n",
       " 'that',\n",
       " 'there',\n",
       " 'can',\n",
       " 'be',\n",
       " 'no',\n",
       " 'possible',\n",
       " 'misunderstanding',\n",
       " 'both',\n",
       " 'Germany',\n",
       " 'and',\n",
       " 'Japan',\n",
       " 'can',\n",
       " 'be',\n",
       " 'certain',\n",
       " 'beyond',\n",
       " 'any',\n",
       " 'shadow',\n",
       " 'of',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'that',\n",
       " 'America',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'the',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'freedom',\n",
       " 'until',\n",
       " 'no',\n",
       " 'vestige',\n",
       " 'of',\n",
       " 'resistance',\n",
       " 'remains',\n",
       " 'We',\n",
       " 'are',\n",
       " 'deeply',\n",
       " 'conscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'much',\n",
       " 'hard',\n",
       " 'fighting',\n",
       " 'is',\n",
       " 'still',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'us',\n",
       " 'Having',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'such',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'to',\n",
       " 'make',\n",
       " 'complete',\n",
       " 'victory',\n",
       " 'certain',\n",
       " 'America',\n",
       " 'will',\n",
       " 'never',\n",
       " 'become',\n",
       " 'a',\n",
       " 'party',\n",
       " 'to',\n",
       " 'any',\n",
       " 'plan',\n",
       " 'for',\n",
       " 'partial',\n",
       " 'victory',\n",
       " 'To',\n",
       " 'settle',\n",
       " 'for',\n",
       " 'merely',\n",
       " 'another',\n",
       " 'temporary',\n",
       " 'respite',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'jeopardize',\n",
       " 'the',\n",
       " 'future',\n",
       " 'security',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Our',\n",
       " 'demand',\n",
       " 'has',\n",
       " 'been',\n",
       " 'and',\n",
       " 'it',\n",
       " 'remains',\n",
       " 'Unconditional',\n",
       " 'Surrender',\n",
       " 'We',\n",
       " 'will',\n",
       " 'not',\n",
       " 'traffic',\n",
       " 'with',\n",
       " 'the',\n",
       " 'breakers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'on',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'The',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'making',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'grave',\n",
       " 'responsibility',\n",
       " 'must',\n",
       " 'rest',\n",
       " 'with',\n",
       " 'the',\n",
       " 'defenders',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'We',\n",
       " 'are',\n",
       " 'not',\n",
       " 'unconscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dictates',\n",
       " 'of',\n",
       " 'humanity',\n",
       " 'We',\n",
       " 'do',\n",
       " 'not',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'see',\n",
       " 'unnecessary',\n",
       " 'or',\n",
       " 'unjustified',\n",
       " 'suffering',\n",
       " 'But',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'Go',\n",
       " 'd',\n",
       " 'and',\n",
       " 'of',\n",
       " 'man',\n",
       " 'have',\n",
       " 'been',\n",
       " 'violated',\n",
       " 'and',\n",
       " 'the',\n",
       " 'guilty',\n",
       " 'must',\n",
       " 'not',\n",
       " 'go',\n",
       " 'unpunished',\n",
       " 'Nothing',\n",
       " 'shall',\n",
       " 'shake',\n",
       " 'our',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'punish',\n",
       " 'the',\n",
       " 'war',\n",
       " 'criminals',\n",
       " 'even',\n",
       " 'though',\n",
       " 'we',\n",
       " 'must',\n",
       " 'pursue',\n",
       " 'them',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ends',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'Lasting',\n",
       " 'peace',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'secured',\n",
       " 'if',\n",
       " 'we',\n",
       " 'permit',\n",
       " 'our',\n",
       " 'dangerous',\n",
       " 'opponents',\n",
       " 'to',\n",
       " 'plot',\n",
       " 'future',\n",
       " 'wars',\n",
       " 'with',\n",
       " 'impunity',\n",
       " 'at',\n",
       " 'any',\n",
       " 'mountain',\n",
       " 'retreat',\n",
       " 'however',\n",
       " 'distant',\n",
       " 'In',\n",
       " 'this',\n",
       " 'shrinking',\n",
       " 'world',\n",
       " 'it',\n",
       " 'is',\n",
       " 'futile',\n",
       " 'to',\n",
       " 'seek',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'geographical',\n",
       " 'barriers',\n",
       " 'Real',\n",
       " 'security',\n",
       " 'will',\n",
       " 'be',\n",
       " 'found',\n",
       " 'only',\n",
       " 'in',\n",
       " 'law',\n",
       " 'and',\n",
       " 'in',\n",
       " 'justice',\n",
       " 'Here',\n",
       " 'in',\n",
       " 'America',\n",
       " 'we',\n",
       " 'have',\n",
       " 'labored',\n",
       " 'long',\n",
       " 'and',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'a',\n",
       " 'social',\n",
       " 'order',\n",
       " 'worthy',\n",
       " 'of',\n",
       " 'our',\n",
       " 'great',\n",
       " 'heritage',\n",
       " 'In',\n",
       " 'our',\n",
       " 'time',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'has',\n",
       " 'been',\n",
       " 'made',\n",
       " 'toward',\n",
       " 'a',\n",
       " 'really',\n",
       " 'democratic',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'assure',\n",
       " 'the',\n",
       " 'forward',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'of',\n",
       " 'America',\n",
       " 'that',\n",
       " 'there',\n",
       " 'w',\n",
       " 'ill',\n",
       " 'be',\n",
       " 'no',\n",
       " 'relaxation',\n",
       " 'in',\n",
       " 'our',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'common',\n",
       " 'people',\n",
       " 'In',\n",
       " 'the',\n",
       " 'difficult',\n",
       " 'days',\n",
       " 'ahead',\n",
       " 'unquestionably',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'staggering',\n",
       " 'proportions',\n",
       " 'However',\n",
       " 'with',\n",
       " 'the',\n",
       " 'faith',\n",
       " 'of',\n",
       " 'our',\n",
       " 'fathers',\n",
       " 'in',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'fear',\n",
       " 'the',\n",
       " 'future',\n",
       " 'On',\n",
       " 'the',\n",
       " 'battlefields',\n",
       " 'we',\n",
       " 'have',\n",
       " 'frequently',\n",
       " 'faced',\n",
       " 'overwhelming',\n",
       " 'odds',\n",
       " 'and',\n",
       " 'won',\n",
       " 'At',\n",
       " 'home',\n",
       " 'Americans',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'less',\n",
       " 'resolute',\n",
       " 'We',\n",
       " 'shall',\n",
       " 'never',\n",
       " 'cease',\n",
       " 'our',\n",
       " 'struggle',\n",
       " 'to',\n",
       " 'preserve',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'our',\n",
       " 'American',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'At',\n",
       " 'this',\n",
       " 'moment',\n",
       " 'America',\n",
       " 'along',\n",
       " 'with',\n",
       " 'her',\n",
       " 'brave',\n",
       " 'Allies',\n",
       " 'is',\n",
       " 'paying',\n",
       " 'again',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'for',\n",
       " 'the',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'our',\n",
       " 'freedom',\n",
       " 'With',\n",
       " 'characteristic',\n",
       " 'energy',\n",
       " 'we',\n",
       " 'are',\n",
       " 'assisting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'liberation',\n",
       " 'of',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'Gradually',\n",
       " 'the',\n",
       " 'shackles',\n",
       " 'of',\n",
       " 'slavery',\n",
       " 'are',\n",
       " 'being',\n",
       " 'broken',\n",
       " 'by',\n",
       " 't',\n",
       " 'he',\n",
       " 'forces',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'All',\n",
       " 'of',\n",
       " 'us',\n",
       " 'are',\n",
       " 'praying',\n",
       " 'for',\n",
       " 'a',\n",
       " 'speedy',\n",
       " 'victory',\n",
       " 'Every',\n",
       " 'day',\n",
       " 'peace',\n",
       " 'is',\n",
       " 'delayed',\n",
       " 'costs',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'toll',\n",
       " 'The',\n",
       " 'armies',\n",
       " 'of',\n",
       " 'liberation',\n",
       " 'today',\n",
       " 'are',\n",
       " 'bringing',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'Hitler',\n",
       " 's',\n",
       " 'ghastly',\n",
       " 'threat',\n",
       " 'to',\n",
       " 'dominate',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Tokyo',\n",
       " 'rocks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'weight',\n",
       " 'of',\n",
       " 'our',\n",
       " 'bombs',\n",
       " 'The',\n",
       " 'grand',\n",
       " 'strategy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'determined',\n",
       " 'due',\n",
       " 'in',\n",
       " 'no',\n",
       " 'small',\n",
       " 'measure',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'our',\n",
       " 'departed',\n",
       " 'Commander',\n",
       " 'in',\n",
       " 'Chief',\n",
       " 'We',\n",
       " 'are',\n",
       " 'now',\n",
       " 'carrying',\n",
       " 'out',\n",
       " 'our',\n",
       " 'part',\n",
       " 'of',\n",
       " 'that',\n",
       " 'strategy',\n",
       " 'under',\n",
       " 'the',\n",
       " 'able',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'Admiral',\n",
       " 'Leahy',\n",
       " 'General',\n",
       " 'Marshall',\n",
       " 'A',\n",
       " 'dmiral',\n",
       " 'King',\n",
       " 'General',\n",
       " 'Arnold',\n",
       " 'General',\n",
       " 'Eisenhower',\n",
       " 'Admiral',\n",
       " 'Nimitz',\n",
       " 'and',\n",
       " 'General',\n",
       " 'MacArthur',\n",
       " 'I',\n",
       " 'want',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'to',\n",
       " 'know',\n",
       " 'that',\n",
       " 'this',\n",
       " 'direction',\n",
       " 'must',\n",
       " 'and',\n",
       " 'will',\n",
       " 'remain',\n",
       " 'unchanged',\n",
       " 'and',\n",
       " 'unhampered',\n",
       " 'Our',\n",
       " 'debt',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heroic',\n",
       " 'men',\n",
       " 'and',\n",
       " 'valiant',\n",
       " 'women',\n",
       " 'in',\n",
       " 'the',\n",
       " 'service',\n",
       " 'of',\n",
       " 'our',\n",
       " 'country',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'repaid',\n",
       " 'They',\n",
       " 'have',\n",
       " 'earned',\n",
       " 'our',\n",
       " 'undying',\n",
       " 'gratitude',\n",
       " 'America',\n",
       " 'will',\n",
       " 'never',\n",
       " 'forget',\n",
       " 'their',\n",
       " 'sacrifices',\n",
       " 'Because',\n",
       " 'of',\n",
       " 'these',\n",
       " 'sacrifices',\n",
       " 'the',\n",
       " 'dawn',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'throughout',\n",
       " 'th',\n",
       " 'e',\n",
       " 'world',\n",
       " 'slowly',\n",
       " 'casts',\n",
       " 'its',\n",
       " 'gleam',\n",
       " 'across',\n",
       " 'the',\n",
       " 'horizon',\n",
       " 'Our',\n",
       " 'forefathers',\n",
       " 'came',\n",
       " 'to',\n",
       " 'our',\n",
       " 'rugged',\n",
       " 'shores',\n",
       " 'in',\n",
       " 'search',\n",
       " 'of',\n",
       " 'religious',\n",
       " 'tolerance',\n",
       " 'political',\n",
       " 'freedom',\n",
       " 'and',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'For',\n",
       " 'those',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'they',\n",
       " 'risked',\n",
       " 'their',\n",
       " 'lives',\n",
       " 'We',\n",
       " 'well',\n",
       " 'know',\n",
       " 'today',\n",
       " 'that',\n",
       " 'such',\n",
       " 'rights',\n",
       " 'can',\n",
       " 'be',\n",
       " 'preserved',\n",
       " 'only',\n",
       " 'by',\n",
       " 'constant',\n",
       " 'vigilance',\n",
       " 'the',\n",
       " 'eternal',\n",
       " 'price',\n",
       " 'of',\n",
       " 'liberty',\n",
       " 'Within',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'after',\n",
       " 'I',\n",
       " 'took',\n",
       " 'the',\n",
       " 'oath',\n",
       " 'of',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "words = [w for w in words if w.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'must': 1568, 'people': 1291, 'world': 1128, 'year': 1097, 'America': 1076, 'us': 1049, 'new': 1049, 'Congress': 1014, 'years': 827, 'American': 784, ...})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words: list[str] = nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('must', 1568), ('people', 1291), ('world', 1128)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fd = nltk.FreqDist([w.lower() for w in fd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(nltk.corpus.state_union.words())\n",
    "text.concordance(\"america\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance_list = text.concordance_list(\"america\", lines=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n"
     ]
    }
   ],
   "source": [
    "for entry in concordance_list:\n",
    "     print(entry.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'United', 'States'), 294), (('the', 'American', 'people'), 185)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.ngram_fd.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ('the', 'United', 'States') ('the', 'American', 'people') \n",
      "                          294                           185 \n"
     ]
    }
   ],
   "source": [
    "finder.ngram_fd.tabulate(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False RT @Natwaah: I wonder how much time Ed Miliband has wasted in these various Q&amp;As and debates by asking people their names and saying \"let m…\n",
      "> True RT @jackfostr: @KennyFarq well, it's a bit selective, because SNP worked with all parties when in minority govt.\n",
      "> False if we vote in large snp group at wm its win/win no matter what else happens\n",
      "> True All Miliband had to say was we'll concentrate on winning as many seats as possible to win a majority.He can't even get that right #GE2015\n",
      "> True RT @AnitaBellows12: RT @Tommy_Colc\n",
      "FT come out in support of Tories claiming Miliband is \"preoccupied w/ inequality\".The man who wrote it h…\n",
      "> True @nejcsvete hi! On our shouting out list you are one of the best, what's your secret behind this?:)@AdeccoWaytoWork #SandroForCEO #CEO1Month\n",
      "> True @afneil ALLWAYS LIKED YOU ANDREW NOW PLAY MY BLOODY RECORD ON ELECTION NIGHT https//t.co/au9gnjoR3t CHEERS MATE !!!\n",
      "> True @dspdavey Gorgeous, Deborah! Good taste! :) You can use coupon code COLOURDEB for red, purple or blue here:  http//t.co/MXEKsnMvvX Thanks!!\n",
      "> True The moment I decide to log onto the account I haven't been on in years is the moment I saw the best thing ever :) http//t.co/pu6B5jodur\n",
      "> False RT @PeatWorrier: \"A vote for the SNP is. Er. A vote for another referendum we insist Holyrood has no legal authority to legislate for\" http…\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def is_positive(review_id: str) -> bool:\n",
    "    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                wordcount += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "\n",
    "    # Adding 1 to the final compound score to always have positive numbers\n",
    "    # since some classifiers you'll use later don't work with negative numbers.\n",
    "    features[\"mean_compound\"] = mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = mean(positive_scores)\n",
    "    features[\"wordcount\"] = wordcount\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.67% - BernoulliNB\n",
      "66.67% - ComplementNB\n",
      "66.67% - MultinomialNB\n",
      "70.13% - KNeighborsClassifier\n",
      "62.60% - DecisionTreeClassifier\n",
      "69.40% - RandomForestClassifier\n",
      "71.73% - LogisticRegression\n",
      "73.33% - MLPClassifier\n",
      "70.80% - AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(features[:train_count])\n",
    "    accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n",
    "    print(F\"{accuracy:.2%} - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
